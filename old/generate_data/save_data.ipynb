{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0SVWIteF1zG",
        "outputId": "66ab256d-1c55-452e-bcdd-5789ca9ef44a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.7.4 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmk9H57TF8yN",
        "outputId": "37da094e-05a3-4ffd-dba4-49842696fd9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1U3yR01F-wC"
      },
      "outputs": [],
      "source": [
        "tf.get_logger().setLevel('ERROR')\n",
        "seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaiRziFxGAh0"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlgnooN9GBwg"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = str(text)\n",
        "    # text = text.lower() # lowercase text\n",
        "    # REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@;]')\n",
        "    # BAD_SYMBOLS_RE = re.compile('[^0-9a-z#+_]')\n",
        "    STOPWORDS = set(nltk.corpus.stopwords.words('english'))\n",
        "    UNWANTED_WORDS = ['copyrights', 'copyright', 'results', 'objectives', 'methods', 'design', 'study population', 'measurements', 'conclusions', 'materials', 'methods', 'limitations', 'setting', 'purpose', 'intervention', 'main outcome', 'measures', 'background']\n",
        "    # text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "    # text = BAD_SYMBOLS_RE.sub(' ', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS and word not in UNWANTED_WORDS) # remove stopwords and UNWANTED_WORDS from text\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inVQJPwQGDxT"
      },
      "outputs": [],
      "source": [
        "def remove_prefix(text, prefix):\n",
        "    if text.startswith(prefix):\n",
        "        return text[len(prefix):]\n",
        "    return text  # or whatever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTVGKRPkGErQ"
      },
      "outputs": [],
      "source": [
        "def preprocess_test(text):\n",
        "  nan_a = text[text['Abstract'].isnull()]\n",
        "  bool_pred = pd.isnull(text['Abstract'])\n",
        "  for i, row in text[bool_pred].iterrows():\n",
        "    text.at[i,'abstract'] = \" \"\n",
        "  text = text.dropna(subset=[\"Abstract\"])\n",
        "  rows, cols = text.shape\n",
        "  print('Removed nan from abstract: Data size: Num of rows: ',rows, ' Num of cols: ',cols)\n",
        "  REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "  BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "  STOPWORDS = set(nltk.corpus.stopwords.words('english'))\n",
        "  UNWANTED_WORDS = ['results', 'objectives', 'methods', 'design', 'study population', 'measurements', 'conclusions', 'materials', 'methods', 'limitations', 'setting', 'patients', 'purpose', 'intervention', 'main outcome', 'measures', 'background']\n",
        "  text['TitlePred'] = text['Title'].apply(clean_text)\n",
        "  text['AbstractPred'] = text['Abstract'].apply(clean_text)\n",
        "  text['TitlePred'] = text['TitlePred'].str.replace('\\d+', '')\n",
        "  text['AbstractPred'] = text['AbstractPred'].str.replace('\\d+', '')\n",
        "  return text, nan_a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AarcbOuJGH3n"
      },
      "source": [
        "# Preprocess Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGGevdpLGK2C"
      },
      "outputs": [],
      "source": [
        "articles = pd.read_csv('/content/gdrive/MyDrive/ESA/sex_diff_screenings.csv')\n",
        "test = pd.read_csv('/content/gdrive/MyDrive/ESA/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJMxFgQZZKs0",
        "outputId": "fbc22644-7e9c-43b2-a4f9-da80afd6fbb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3999, 23)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "articles.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCETZ3seZMUC",
        "outputId": "39b49c8b-1a6c-4e0b-e962-e4eba11ca62e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 22)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XuaiTq_Zk-w"
      },
      "outputs": [],
      "source": [
        "test['Decision'] = test['ScreeningDecisions']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-wQie2MZRDK"
      },
      "outputs": [],
      "source": [
        "# articles_merged = articles.append(test, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yufszD0SZWXU",
        "outputId": "631a1afa-735a-4ae7-ca37-db3f44ce1fb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       Excluded\n",
              "1       Excluded\n",
              "2       Excluded\n",
              "3       Included\n",
              "4       Excluded\n",
              "          ...   \n",
              "5835    Excluded\n",
              "5836    Excluded\n",
              "5837    Excluded\n",
              "5838    Excluded\n",
              "5839    Excluded\n",
              "Name: Decision, Length: 5840, dtype: object"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# articles_merged['Decision']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxMF65kUGgEb",
        "outputId": "57df2a6a-2a4c-47e7-b48b-66ed50fcc426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed nan from abstract: Data size: Num of rows:  5239  Num of cols:  34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-65ffb8115e33>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  text['TitlePred'] = text['Title'].apply(clean_text)\n",
            "<ipython-input-8-65ffb8115e33>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  text['AbstractPred'] = text['Abstract'].apply(clean_text)\n",
            "<ipython-input-8-65ffb8115e33>:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  text['TitlePred'] = text['TitlePred'].str.replace('\\d+', '')\n",
            "<ipython-input-8-65ffb8115e33>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  text['TitlePred'] = text['TitlePred'].str.replace('\\d+', '')\n",
            "<ipython-input-8-65ffb8115e33>:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  text['AbstractPred'] = text['AbstractPred'].str.replace('\\d+', '')\n",
            "<ipython-input-8-65ffb8115e33>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  text['AbstractPred'] = text['AbstractPred'].str.replace('\\d+', '')\n"
          ]
        }
      ],
      "source": [
        "# articles_merged, nan = preprocess_test(articles_merged);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GncxVi0x9Ql",
        "outputId": "4d10f57d-a98d-41bb-f7e6-ba7a5a0e9494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed nan from abstract: Data size: Num of rows:  3631  Num of cols:  24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-65ffb8115e33>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  text['TitlePred'] = text['Title'].apply(clean_text)\n",
            "<ipython-input-8-65ffb8115e33>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  text['AbstractPred'] = text['Abstract'].apply(clean_text)\n",
            "<ipython-input-8-65ffb8115e33>:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  text['TitlePred'] = text['TitlePred'].str.replace('\\d+', '')\n",
            "<ipython-input-8-65ffb8115e33>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  text['TitlePred'] = text['TitlePred'].str.replace('\\d+', '')\n",
            "<ipython-input-8-65ffb8115e33>:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  text['AbstractPred'] = text['AbstractPred'].str.replace('\\d+', '')\n",
            "<ipython-input-8-65ffb8115e33>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  text['AbstractPred'] = text['AbstractPred'].str.replace('\\d+', '')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed nan from abstract: Data size: Num of rows:  1000  Num of cols:  23\n"
          ]
        }
      ],
      "source": [
        "articles, nan = preprocess_test(articles);\n",
        "test, nan = preprocess_test(test);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S610e89AGpe7"
      },
      "outputs": [],
      "source": [
        "articles = articles.drop_duplicates(subset=[\"TitlePred\"])\n",
        "articles = articles.drop_duplicates(subset=['AbstractPred'])\n",
        "test = test.drop_duplicates(subset=[\"TitlePred\"])\n",
        "test = test.drop_duplicates(subset=['AbstractPred'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZlCjKyyGtkk"
      },
      "outputs": [],
      "source": [
        "articles[\"titleabstract\"] = articles[\"TitlePred\"] + \" \" + articles[\"AbstractPred\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfzwoefwybaf"
      },
      "outputs": [],
      "source": [
        "test[\"titleabstract\"] = test[\"TitlePred\"] + \" \" + test[\"AbstractPred\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQWA3cqEIXQ3"
      },
      "outputs": [],
      "source": [
        "X = articles['titleabstract'].values\n",
        "Y = articles['Decision'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3hoTkwwwb7G"
      },
      "outputs": [],
      "source": [
        "titles = articles['TitlePred'].values\n",
        "abstracts = articles['AbstractPred'].values\n",
        "Y = articles['Decision'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55wKHhN7Imqa"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 2021)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ1e9-W1aXXC"
      },
      "outputs": [],
      "source": [
        "nr_train = int(np.ceil(titles.shape[0]*0.9))\n",
        "# nr_val = int(np.ceil(titles.shape[0]*0.9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obgHMWYqB2WR"
      },
      "outputs": [],
      "source": [
        "titles_train = titles[0:nr_train]\n",
        "abstracts_train = abstracts[0:nr_train]\n",
        "Y_train = Y[0:nr_train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1UEfryua2Ti"
      },
      "outputs": [],
      "source": [
        "titles_val = titles[nr_train:]\n",
        "abstracts_val = abstracts[nr_train:]\n",
        "Y_val = Y[nr_train:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzQJpFMnbKlz"
      },
      "outputs": [],
      "source": [
        "titles_test = titles[nr_val:]\n",
        "abstracts_test = abstracts[nr_val:]\n",
        "Y_test = Y[nr_val:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo2IlGKjIpa-"
      },
      "outputs": [],
      "source": [
        "train_data = {\"titles\": titles_train, \"abstracts\": abstracts_train, 'decision': Y_train}\n",
        "train_df = pd.DataFrame(data=train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7TYV4FVb35A"
      },
      "outputs": [],
      "source": [
        "train_df['titleabstract'] = train_df['titles'] + '. ' + train_df['abstracts']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo5GIgh3JGPP"
      },
      "outputs": [],
      "source": [
        "val_data = {\"titles\": titles_val, \"abstracts\": abstracts_val, 'decision': Y_val}\n",
        "val_df = pd.DataFrame(data=val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5bKoZYgcRab"
      },
      "outputs": [],
      "source": [
        "val_df['titleabstract'] = val_df['titles'] + '. ' + val_df['abstracts']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7MaKQz3cVFe"
      },
      "outputs": [],
      "source": [
        "test_data = {\"titles\": titles_test, \"abstracts\": abstracts_test, 'decision': Y_test}\n",
        "test_df = pd.DataFrame(data=test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVMrzzMbcc4V"
      },
      "outputs": [],
      "source": [
        "test_df['titleabstract'] = test_df['titles'] + '. ' + test_df['abstracts']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "ubFypP29gM4T",
        "outputId": "f8754802-0e0b-428f-8859-95b9204cf2c3"
      },
      "outputs": [],
      "source": [
        "test_df[test_df.decision == 'Included'].shape[0] / test_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCjCFnQngUhV",
        "outputId": "ff79e778-30c1-489b-a13d-b803cd25072e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.04709141274238227"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df[val_df.decision == 'Included'].shape[0] / val_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9gvncPYgYW_",
        "outputId": "eb911b69-1bca-4482-8996-532c6e0c2af1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.06263432606693276"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[train_df.decision == 'Included'].shape[0] / train_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvfzLSBBJ3MI"
      },
      "outputs": [],
      "source": [
        "train_df.to_csv(\"sex_diff_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvbN5xr4KNCn"
      },
      "outputs": [],
      "source": [
        "val_df.to_csv(\"sex_diff_val.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2O83YwehNPF"
      },
      "outputs": [],
      "source": [
        "test.to_csv(\"sex_diff_test.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
